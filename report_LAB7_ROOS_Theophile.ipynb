{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 07: Nonlinear optimisation: Matrix factorization\n",
    "\n",
    "This exercise will introduce an advanced version of non-linear optimization - the use of a gradient descent algorithm in a  movie recommender system. To achieve this aim we will introduce RMSE evaluation metric, 10-fold cross validation and the Matrix Factorization algorithm.\n",
    "\n",
    "## Recommender Systems\n",
    "Recommender systems were developed as a solution to the overwhelming number of content items available to the user. With the rapid growth of the internet availability the ease of multimedia item production the user can quickly become unable to chose what to watch / listen / read since he/she has too many items to chose from.\n",
    "Recommender systems have developed as a solution to this problem. They work in many different ways - from looking for people with similar taste (Collaborative Recommender Systems) to discerning each user’s particular taste (Content-based Recommender Systems) to any combination of approaches (Hybrid Recommender System).\n",
    "Regardless of the approach they require some setup - determining the optimum setting values to achieve the best performance. \n",
    "For this exercise we will focus on the Matrix Factorization approach which is one of the better known Collaborative algorithms.\n",
    "\n",
    "The explanation of Matrix factorization is available in the literature:\n",
    "https://e.fe.uni-lj.si/mod/folder/view.php?id=10996\n",
    "\n",
    "\n",
    "## Matrix Factorization\n",
    "The Matrix Factorization (MF) approach works by transforming the user-item matrix into a feature space that has some similarities with the PCA approach. The aim of the algorithm is to generate a set of latent features for each existing user and item. Any rating can then be calculated with the help of a dot product of the feature vector of the user who is looking for a recommendation and the feature vector of the potentially interesting multimedia item. \n",
    "\n",
    "\n",
    "## Base equation\n",
    "The basic equation for predicted rating calculation is \n",
    "$r = b + b_u+b_i+p*q$\n",
    "With $b$ being the global bias (database average rating), $b_u$ user bias, $b_i$ item bias and the $p*q$ the dot product of the feature vectors.\n",
    "\n",
    "## Feature calculation\n",
    "The challenge of the MF approach lies in the feature calculation. Since most of the user-item matrix features empty values (i.e. the users did not rate the items yet) we cannot use a direct PCA approach. Instead we use a gradient descent based approach that tries to set the feature values in such a way that the calculated rating match the actual ratings as close as possible.\n",
    " \n",
    "The approach works (for each rating):\n",
    "* Calculate the current predicted rating\n",
    "* Error is the difference between the calculated rating and the true rating in the dataset\n",
    "* Use the following two equations to set the value of the current latent feature\n",
    " - tmpUF =tempUF + (error *tempIF -regularization *tempUF) *pLearningRate\n",
    " - tmpIF = tempIF + (error *tempUF -regularization *tempIF) *qLearningRate \n",
    "\n",
    "The approach therefore features a set of parameters, that can be optimized to minimize the error of the prediction.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As usual we must import our data, prepare the dataset and initialize our values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03\n"
     ]
    }
   ],
   "source": [
    "# Po potrebi je potrebno instalirati scikit-learn \n",
    "#  %pip install scikit-learn\n",
    "\n",
    "import algorithm as alg\n",
    "import logging\n",
    "import DataParser as dp\n",
    "import bralec as cnf\n",
    "\n",
    "# CONFIGURATION PARAMETERS\n",
    "#cnf.GE_cf.set(\"datasetFolding\",\"fold\",\"True\") #to fold or not to fold\n",
    "cnf.GE_cf.set(\"datasetFolding\",\"fold\",\"False\") #to fold or not to fold\n",
    "\n",
    "# SELECT DATA SET\n",
    "# cnf.GE_cf.set(\"dataSet\",\"dataName\",\"CoMoDa_small.txt\")\n",
    "cnf.GE_cf.set(\"dataSet\",\"dataName\",\"CoMoDa_500.txt\")\n",
    "\n",
    "# Configure number of folds\n",
    "cnf.GE_cf.set(\"datasetFolding\", \"numOfFolds\", \"5\")\n",
    "\n",
    "# Create training and testing data set \n",
    "dp.createTrainTestSet()\n",
    "test = alg.Algorithm()\n",
    "\n",
    "# Size of feature vector, representing users and items\n",
    "test.numOfFeatures = 2\n",
    "# Learning rate (speed)\n",
    "test.pLearningRate = 0.2\n",
    "test.qLearningRate = 0.2\n",
    "# Regularization \n",
    "test.regularization = 0.5\n",
    "# Starting value of features\n",
    "test.initFeatureValue = 0.2\n",
    "# Number of iterations\n",
    "test.numofiterations = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.100e+01 3.584e+03 4.000e+00]\n",
      " [6.100e+01 1.610e+02 5.000e+00]\n",
      " [5.500e+01 1.920e+02 4.000e+00]\n",
      " ...\n",
      " [6.100e+01 1.630e+02 2.000e+00]\n",
      " [3.500e+01 1.300e+01 3.000e+00]\n",
      " [5.600e+01 1.070e+02 3.000e+00]]\n",
      "(400, 3)\n"
     ]
    }
   ],
   "source": [
    "# Preveri učno množico podatkov - training set\n",
    "trset = dp.db.trainSet\n",
    "print(dp.db.trainSet)\n",
    "print(dp.db.trainSet.shape)\n",
    "\n",
    "# Preveri velikost testne množice\n",
    "\n",
    "\n",
    "# Koliko je vhodnih podatkov ?\n",
    "# Kako so razdeljeni v učno in testno množico ? \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "In order to evaluate the efficiency of the settings we will use the RMSE and 10-fold cross validation.\n",
    "\n",
    "### RMSE\n",
    "RMSE is one of the “standard” approaches in RS. It calculates the Root Mean Square Error - the difference between the predicted and the true rating.\n",
    "$RMSE = \\sqrt{\\frac{\\sum_1^{N}(\\hat{r}-r)^2}{N}}$\n",
    "\n",
    " \n",
    "So the lower the value, the better our system fits the values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Calculating baseline\n",
      "INFO -  MaxUserId = 157\n",
      "INFO -  MaxItemId = 3646\n",
      "INFO - Feature = 0\n",
      "INFO - Feature = 1\n",
      "INFO - MF algorithm RMSE = 1.109444871903794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.109444871903794\n",
      "CPU times: user 4.96 s, sys: 9.53 ms, total: 4.97 s\n",
      "Wall time: 5.1 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "\n",
    "# Poženemo učenje na učni množici, in dobimo rezultat evaluacije napake na testni množici.\n",
    "print (test.getBaseline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.109444871903794"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rezultat - napaka na trenutni testni množici\n",
    "test.evaluateModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Križna validacija: 10-fold cross validation\n",
    "\n",
    "There often exists a set of setting values that performs extraordinarily on one set of data well but fails on all other sets. We are of course interested in values that would perform well in any environment. In order to find this we use the 10-fold cross validation approach - we split the data set into 10 parts and use 9 parts for training and 1 part for evaluation and repeat this 10 times - each time using different part for evaluation. This ensures that our parameters work well with different combinations of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03\n"
     ]
    }
   ],
   "source": [
    "# CONFIGURATION PARAMETERS\n",
    "cnf.GE_cf.set(\"datasetFolding\",\"fold\",\"True\") #to fold or not to fold\n",
    "\n",
    "# SELECT DATA SET\n",
    "# cnf.GE_cf.set(\"dataSet\",\"dataName\",\"CoMoDa_small.txt\")\n",
    "cnf.GE_cf.set(\"dataSet\",\"dataName\",\"CoMoDa_500.txt\")\n",
    "\n",
    "# Configure number of folds\n",
    "cnf.GE_cf.set(\"datasetFolding\", \"numOfFolds\", \"2\")\n",
    "\n",
    "# Create training and testing data set \n",
    "dp.createTrainTestSet()\n",
    "test = alg.Algorithm()\n",
    "\n",
    "# Size of feature vector, representing users and items\n",
    "test.numOfFeatures = 3\n",
    "# Learning rate (speed)\n",
    "test.pLearningRate = 0.2\n",
    "test.qLearningRate = 0.2\n",
    "# Regularization \n",
    "test.regularization = 0.5\n",
    "# Starting value of features\n",
    "test.initFeatureValue = 0.2\n",
    "# Number of iterations\n",
    "test.numofiterations = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Calculating folded baseline: 2\n",
      "INFO -  MaxUserId = 103\n",
      "INFO -  MaxItemId = 3646\n",
      "INFO - Feature = 0\n",
      "INFO - Feature = 1\n",
      "INFO - Feature = 2\n",
      "INFO -  MaxUserId = 157\n",
      "INFO -  MaxItemId = 179\n",
      "INFO - Feature = 0\n",
      "INFO - Feature = 1\n",
      "INFO - Feature = 2\n",
      "INFO - MF algorithm RMSE = 1.1288733134791702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1288733134791702\n",
      "CPU times: user 7.94 s, sys: 12.5 ms, total: 7.95 s\n",
      "Wall time: 8.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print (test.getBaseline())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "Perform tests with different number of folds : no folding (0), 2 folds, 5, and 10, observing the error (RMSE) and computation time. \n",
    "\n",
    "How does the number of folds affect reliability of the estimated error (RMSE) ? \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NO FOLDING\n",
      "0.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%time` not found.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2:\n",
    "\n",
    "Perform tests with varying number of features : 1,2,4,6,8,10\n",
    "\n",
    "Calculate error (RMSE), and present results in a table or a graph.\n",
    "\n",
    "How does increasing number of features affect the error ? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03\n"
     ]
    }
   ],
   "source": [
    "# CONFIGURATION PARAMETERS\n",
    "cnf.GE_cf.set(\"datasetFolding\",\"fold\",\"True\") #to fold or not to fold\n",
    "\n",
    "# SELECT DATA SET\n",
    "# cnf.GE_cf.set(\"dataSet\",\"dataName\",\"CoMoDa_small.txt\")\n",
    "cnf.GE_cf.set(\"dataSet\",\"dataName\",\"CoMoDa_500.txt\")\n",
    "\n",
    "# Configure number of folds\n",
    "cnf.GE_cf.set(\"datasetFolding\", \"numOfFolds\", \"5\")\n",
    "\n",
    "# Create training and testing data set \n",
    "dp.createTrainTestSet()\n",
    "test = alg.Algorithm()\n",
    "\n",
    "# Size of feature vector, representing users and items\n",
    "test.numOfFeatures = 1\n",
    "# Learning rate (speed)\n",
    "test.pLearningRate = 0.2\n",
    "test.qLearningRate = 0.2\n",
    "# Regularization \n",
    "test.regularization = 0.5\n",
    "# Starting value of features\n",
    "test.initFeatureValue = 0.2\n",
    "# Number of iterations\n",
    "test.numofiterations = 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Calculating folded baseline: 5\n",
      "INFO -  MaxUserId = 157\n",
      "INFO -  MaxItemId = 3646\n",
      "INFO - Feature = 0\n",
      "INFO -  MaxUserId = 103\n",
      "INFO -  MaxItemId = 3646\n",
      "INFO - Feature = 0\n",
      "INFO -  MaxUserId = 157\n",
      "INFO -  MaxItemId = 3646\n",
      "INFO - Feature = 0\n",
      "INFO -  MaxUserId = 157\n",
      "INFO -  MaxItemId = 3585\n",
      "INFO - Feature = 0\n",
      "INFO -  MaxUserId = 157\n",
      "INFO -  MaxItemId = 3646\n",
      "INFO - Feature = 0\n",
      "INFO - MF algorithm RMSE = 1.1246816233480064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1246816233480064\n",
      "CPU times: user 12.1 s, sys: 24 ms, total: 12.1 s\n",
      "Wall time: 12.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print (test.getBaseline())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 \n",
    "* Test the effect of regularization, by testing values 0.1, 0.2, 0.4, 0.6, 0.8 (number of features is 5). Plot the resulting RMSE.\n",
    "\n",
    "* (Bonus) Test the effect of learning rate, by testing values 0.1, 0.2, 0.4, 0.6, 0.8 (number of features is 5). Plot the resulting RMSE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "f9b054c170a5091e78c711b969607cef481e4558d560a5a596815aab1a12e7a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
